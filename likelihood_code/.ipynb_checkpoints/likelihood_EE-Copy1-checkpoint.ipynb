{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#%matplotlib inline\n",
    "#%config InlineBackend.figure_format = 'retina'\n",
    "import sys, platform, os\n",
    "import matplotlib\n",
    "from matplotlib import pyplot as plt\n",
    "import numpy as np\n",
    "import camb\n",
    "import pandas as pd\n",
    "import healpy as hp\n",
    "from camb import model, initialpower\n",
    "\n",
    "#Set up a new set of parameters for CAMB\n",
    "pars = camb.CAMBparams()\n",
    "Nside_red=16\n",
    "Nside=512\n",
    "lmax=3*Nside_red-1\n",
    "l_gen=4*Nside\n",
    "#pars.set_cosmology(H0=67.5, ombh2=0.022, omch2=0.122, mnu=0.06, omk=0, tau=0.06)\n",
    "#pars.InitPower.set_params(As=2e-9, ns=0.965, r\n",
    "\n",
    "const=1.88 * 10**(-9)\n",
    "tau=0.07\n",
    "# In[4]:\n",
    "#This function sets up CosmoMC-like settings, with one massive neutrino and helium set using BBN consistency\n",
    "pars.set_cosmology(H0=67.32, ombh2=0.02237, omch2=0.1201, mnu=0.06, omk=0, tau=tau)\n",
    "pars.InitPower.set_params(As=const*np.exp(2*tau), ns=0.9651, r=0)\n",
    "pars.set_for_lmax(l_gen, lens_potential_accuracy=0)\n",
    "results = camb.get_results(pars)\n",
    "powers =results.get_cmb_power_spectra(pars, CMB_unit='muK',raw_cl=False)#spectra are multiplied by l*(l+1)/2pi\n",
    "totCL=powers['total']\n",
    "ls = np.arange(totCL.shape[0])\n",
    "cl_obs=np.asarray(totCL[0:lmax,1])\n",
    "ell = np.arange(0,lmax+1)\n",
    "print(totCL[0:lmax,0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f_ = np.load('/home/amorelli/cl_generator/outfile_0.npz')\n",
    "#https://numpy.org/doc/stable/reference/generated/numpy.concatenate.html if i have multiple npz files\n",
    "\n",
    "print(f_.files) #give the keywords for the stored arrays\n",
    "data_in=f_[\"data\"]\n",
    "tau_in=f_[\"tau\"]\n",
    "print(data_in.shape)\n",
    "#print(data[:15,0,2])\n",
    "data=data_in[:]\n",
    "tau=tau_in[:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "high_nside = 512\n",
    "low_nside= 16\n",
    "window=hp.pixwin(low_nside,lmax=lmax, pol=False)\n",
    "res=hp.nside2resol(low_nside)#, arcmin=False) #false give output in radians\n",
    "beam=hp.gauss_beam(2*res, lmax=lmax, pol=False)\n",
    "res_low=hp.nside2resol(low_nside)#, arcmin=False) \n",
    "#res_high=hp.nside2resol(high_nside, arcmin=False)\n",
    "n_pix=hp.nside2npix(low_nside)\n",
    "#print(res_low,res_high,n_pix)\n",
    "sensitivity=4 #muK-arcmin\n",
    "mu, sigma = 0, sensitivity*np.deg2rad(1./60.)/res\n",
    "#Nl=(sigma*hp.nside2resol(512))**2\n",
    "#print(res_low,hp.nside2resol(16))\n",
    "Nl=(sensitivity*np.deg2rad(1.0/60.0))**2\n",
    "#print(beam.shape)\n",
    "smooth=beam*window\n",
    "print(2*hp.nside2resol(low_nside,arcmin=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#i prepare the data\n",
    "#print(cl_obs)\n",
    "#print(data[0,0,:])\n",
    "def normalize_cl(input_cl):\n",
    "    output_cl=np.zeros(len(input_cl))\n",
    "    for i in range(1,len(input_cl)):\n",
    "        output_cl[i]=input_cl[i]/i/(i+1)*2*np.pi\n",
    "    return output_cl\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_cl=np.zeros((len(tau)+1, lmax))\n",
    "all_cl[0]=normalize_cl(cl_obs)*(smooth[:lmax])**2+Nl#*ell[:lmax]*(ell[:lmax]+1)/2/np.pi\n",
    "for i in range(1,len(tau)+1):\n",
    "    d=data[i-1,1,:]\n",
    "    all_cl[i]=normalize_cl(d)*(smooth[:lmax])**2+Nl#*ell[:lmax]*(ell[:lmax]+1)/2/np.pi\n",
    "print(all_cl.shape)\n",
    "#print(tau[:2],all_cl[:3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_likelihood(c_obs,c_th,l): #cl_th wants all the cl for all the tau\n",
    "    cl_obs=c_obs[l]\n",
    "    cl_th=c_th[:,l]\n",
    "    cl_obs*=1#*l*(l+1)/2/np.pi\n",
    "    logL=np.zeros(len(cl_th))\n",
    "    const=30\n",
    "    #L_l becomes L_l*e^const\n",
    "    for i,cl in enumerate(cl_th):\n",
    "        #print(cl_obs,cl)\n",
    "        #print(cl)\n",
    "        cl_r=cl#*l*(l+1)/2/np.pi\n",
    "        #print(cl_r)\n",
    "        logL_i=-(2*l+1)/2*((cl_obs/cl_r)+np.log(np.abs(cl_r))-1-np.log(np.abs(cl_obs)))\n",
    "        #print(np.log(np.abs(cl_r)),logL_i)\n",
    "        #logL_i=-(2*l+1)/2*((cl/cl_obs)+np.log(np.abs(cl_obs)))\n",
    "        logL[i]=logL_i\n",
    "    return(logL)\n",
    "logL=0\n",
    "l=lmax\n",
    "#c=10**90\n",
    "for l in ell[2:l]:\n",
    "    logL+=compute_likelihood(all_cl[0],all_cl[1:],l)\n",
    "L_l=np.exp(logL)\n",
    "print(logL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(tau,L_l,color='r',linestyle='None',marker='.', markersize = 1.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#L_l=(L_l-np.mean(L_l))/np.std(L_l)\n",
    "#plt.plot(tau,L_l,color='r',linestyle='None',marker='.', markersize = 1.0)\n",
    "from scipy.integrate import trapz, simps\n",
    "def unison_sorted_copies(a, b, c):\n",
    "    assert len(a) == len(b)\n",
    "    assert len(a) == len(c)\n",
    "    p = a.argsort()\n",
    "    return a[p], b[p],c[p]\n",
    "tau, L_l, logL=unison_sorted_copies(tau,L_l, logL)\n",
    "print(tau)\n",
    "#print(tau)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "A=trapz(L_l, tau)\n",
    "print(A)\n",
    "L_l=L_l/A\n",
    "print(trapz(L_l, tau))\n",
    "mean=trapz(L_l*tau, tau)\n",
    "print(mean)\n",
    "var=trapz(L_l*(tau-mean)**2,tau)\n",
    "print(var)\n",
    "sigma=var**0.5\n",
    "print(sigma)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.interpolate import interp1d\n",
    "tausover = np.linspace(0.01,0.13,100000)\n",
    "\n",
    "likeover = interp1d(tau,logL,kind='cubic')(tausover)\n",
    "probover = np.exp(likeover)\n",
    "\n",
    "plt.plot(tausover,probover)\n",
    "\n",
    "meantau = np.sum(probover*tausover)/np.sum(probover)\n",
    "sigmatau = np.sqrt(np.sum(probover*tausover**2)/np.sum(probover) - meantau**2)\n",
    "print(meantau,sigmatau)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "camb-kernel",
   "language": "python",
   "name": "camb-kernel"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
