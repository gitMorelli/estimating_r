{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['/home/amorelli/foreground_noise_maps/noise_generation/ncore=48_seed=70.npz', '/home/amorelli/foreground_noise_maps/noise_generation/ncore=48_seed=112.npz', '/home/amorelli/foreground_noise_maps/noise_generation/ncore=48_seed=115.npz', '/home/amorelli/foreground_noise_maps/noise_generation/ncore=48_seed=71.npz', '/home/amorelli/foreground_noise_maps/noise_generation/ncore=48_seed=113.npz', '/home/amorelli/foreground_noise_maps/noise_generation/ncore=48_seed=88.npz', '/home/amorelli/foreground_noise_maps/noise_generation/ncore=48_seed=109.npz', '/home/amorelli/foreground_noise_maps/noise_generation/ncore=48_seed=74.npz', '/home/amorelli/foreground_noise_maps/noise_generation/ncore=48_seed=98.npz', '/home/amorelli/foreground_noise_maps/noise_generation/ncore=48_seed=89.npz', '/home/amorelli/foreground_noise_maps/noise_generation/ncore=48_seed=77.npz', '/home/amorelli/foreground_noise_maps/noise_generation/ncore=48_seed=94.npz', '/home/amorelli/foreground_noise_maps/noise_generation/ncore=48_seed=83.npz', '/home/amorelli/foreground_noise_maps/noise_generation/ncore=48_seed=100.npz', '/home/amorelli/foreground_noise_maps/noise_generation/ncore=48_seed=97.npz', '/home/amorelli/foreground_noise_maps/noise_generation/ncore=48_seed=95.npz', '/home/amorelli/foreground_noise_maps/noise_generation/ncore=48_seed=108.npz', '/home/amorelli/foreground_noise_maps/noise_generation/ncore=48_seed=104.npz', '/home/amorelli/foreground_noise_maps/noise_generation/ncore=48_seed=103.npz', '/home/amorelli/foreground_noise_maps/noise_generation/d0s0_file.npz', '/home/amorelli/foreground_noise_maps/noise_generation/ncore=48_seed=91.npz', '/home/amorelli/foreground_noise_maps/noise_generation/ncore=48_seed=106.npz', '/home/amorelli/foreground_noise_maps/noise_generation/ncore=48_seed=75.npz', '/home/amorelli/foreground_noise_maps/noise_generation/ncore=48_seed=80.npz', '/home/amorelli/foreground_noise_maps/noise_generation/ncore=48_seed=78.npz', '/home/amorelli/foreground_noise_maps/noise_generation/ncore=48_seed=86.npz', '/home/amorelli/foreground_noise_maps/noise_generation/ncore=48_seed=102.npz', '/home/amorelli/foreground_noise_maps/noise_generation/ncore=48_seed=82.npz', '/home/amorelli/foreground_noise_maps/noise_generation/ncore=48_seed=92.npz', '/home/amorelli/foreground_noise_maps/noise_generation/ncore=48_seed=73.npz', '/home/amorelli/foreground_noise_maps/noise_generation/ncore=48_seed=111.npz', '/home/amorelli/foreground_noise_maps/noise_generation/ncore=48_seed=99.npz', '/home/amorelli/foreground_noise_maps/noise_generation/ncore=48_seed=85.npz', '/home/amorelli/foreground_noise_maps/noise_generation/ncore=48_seed=114.npz', '/home/amorelli/foreground_noise_maps/noise_generation/ncore=48_seed=72.npz', '/home/amorelli/foreground_noise_maps/noise_generation/ncore=48_seed=90.npz', '/home/amorelli/foreground_noise_maps/noise_generation/ncore=48_seed=101.npz', '/home/amorelli/foreground_noise_maps/noise_generation/ncore=48_seed=93.npz', '/home/amorelli/foreground_noise_maps/noise_generation/ncore=48_seed=87.npz', '/home/amorelli/foreground_noise_maps/noise_generation/ncore=48_seed=81.npz', '/home/amorelli/foreground_noise_maps/noise_generation/ncore=48_seed=110.npz', '/home/amorelli/foreground_noise_maps/noise_generation/ncore=48_seed=107.npz', '/home/amorelli/foreground_noise_maps/noise_generation/ncore=48_seed=105.npz', '/home/amorelli/foreground_noise_maps/noise_generation/ncore=48_seed=96.npz', '/home/amorelli/foreground_noise_maps/noise_generation/ncore=48_seed=116.npz', '/home/amorelli/foreground_noise_maps/noise_generation/ncore=48_seed=84.npz', '/home/amorelli/foreground_noise_maps/noise_generation/ncore=48_seed=79.npz', '/home/amorelli/foreground_noise_maps/noise_generation/ncore=48_seed=117.npz', '/home/amorelli/foreground_noise_maps/noise_generation/ncore=48_seed=76.npz']\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "'QU_noise is not a file in the archive'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[4], line 79\u001b[0m\n\u001b[1;32m     77\u001b[0m     input_files[i]\u001b[38;5;241m=\u001b[39minput_folder\u001b[38;5;241m+\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m/\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m+\u001b[39minput_files[i]\n\u001b[1;32m     78\u001b[0m \u001b[38;5;28mprint\u001b[39m(input_files)\n\u001b[0;32m---> 79\u001b[0m noise_maps\u001b[38;5;241m=\u001b[39m\u001b[43muf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgenerate_noise_maps\u001b[49m\u001b[43m(\u001b[49m\u001b[43mn_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43mn_channels\u001b[49m\u001b[43m,\u001b[49m\u001b[43mnside\u001b[49m\u001b[43m,\u001b[49m\u001b[43mpol\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m2\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43msensitivity\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msensitivity\u001b[49m\u001b[43m,\u001b[49m\u001b[43minput_files\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minput_files\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     80\u001b[0m \u001b[38;5;28mprint\u001b[39m(noise_maps\u001b[38;5;241m.\u001b[39mshape)\n\u001b[1;32m     82\u001b[0m maps_per_cl_gen\u001b[38;5;241m=\u001b[39muf\u001b[38;5;241m.\u001b[39mmaps_per_cl(distribution\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\n",
      "File \u001b[0;32m~/pipeline/useful_functions.py:186\u001b[0m, in \u001b[0;36mgenerate_noise_maps\u001b[0;34m(n_train, n_channels, nside, pol, sensitivity, input_files)\u001b[0m\n\u001b[1;32m    184\u001b[0m data\u001b[38;5;241m=\u001b[39mnp\u001b[38;5;241m.\u001b[39mzeros((n_input,n_pix,data_example\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m]))\u001b[38;5;66;03m#i create a container that merge the noise from the multiple files\u001b[39;00m\n\u001b[1;32m    185\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i,file \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(f_) :\n\u001b[0;32m--> 186\u001b[0m     data[i\u001b[38;5;241m*\u001b[39mdim_example:(i\u001b[38;5;241m+\u001b[39m\u001b[38;5;241m1\u001b[39m)\u001b[38;5;241m*\u001b[39mdim_example]\u001b[38;5;241m=\u001b[39m\u001b[43mfile\u001b[49m\u001b[43m[\u001b[49m\u001b[43mlabel\u001b[49m\u001b[43m]\u001b[49m\n\u001b[1;32m    187\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m n_input\u001b[38;5;241m<\u001b[39mn_train:\n\u001b[1;32m    188\u001b[0m     diff\u001b[38;5;241m=\u001b[39mn_train\u001b[38;5;241m-\u001b[39mn_input\n",
      "File \u001b[0;32m~/.conda/envs/camb/lib/python3.9/site-packages/numpy/lib/npyio.py:260\u001b[0m, in \u001b[0;36mNpzFile.__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m    258\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mzip\u001b[38;5;241m.\u001b[39mread(key)\n\u001b[1;32m    259\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 260\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m is not a file in the archive\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m%\u001b[39m key)\n",
      "\u001b[0;31mKeyError\u001b[0m: 'QU_noise is not a file in the archive'"
     ]
    }
   ],
   "source": [
    "#!/usr/bin/env python\n",
    "# coding: utf-8\n",
    "\n",
    "#i import the necessary libraries\n",
    "import sys\n",
    "import os, shutil\n",
    "import h5py\n",
    "import numpy as np\n",
    "import healpy as hp\n",
    "import tensorflow as tf\n",
    "import random as python_random\n",
    "import nnhealpix.layers\n",
    "from tensorflow.keras import metrics\n",
    "import pandas as pd\n",
    "from loss_functions import sigma_loss, sigma2_loss,sigma_batch_loss,sigma_norm_loss,sigma_log_loss,mse_tau,mse_sigma, mse_batch, sigma_f_loss\n",
    "import math\n",
    "import useful_functions as uf\n",
    "import NN_functions as nuf\n",
    "\n",
    "seed_train=33\n",
    "np.random.seed(seed_train)# i set a random seed for the generation of the maps for reproducibility\n",
    "\n",
    "#map gen\n",
    "nside = 16\n",
    "n_train=100 #the total number of training+validation pair of maps that i will generate\n",
    "n_train_fix=40 #the total number of of training maps i will spread on all the r interval -> for each r value i generate n_train_fix/len(r) maps \n",
    "kind_of_map=\"QU\"\n",
    "n_channels=2\n",
    "pol=2\n",
    "res=hp.nside2resol(nside, arcmin=False) \n",
    "sensitivity=4\n",
    "\n",
    "name='xx_xx_xx'\n",
    "base_dir='/home/amorelli/QU_foreground_tau/'+name+'/'\n",
    "# callbacks\n",
    "reduce_lr_on_plateau = True\n",
    "p_stopping=20\n",
    "p_reduce=5\n",
    "f_reduce=0.5\n",
    "stopping_monitor=\"val_mse_batch\"\n",
    "reduce_monitor=\"val_loss\"\n",
    "metrics=[sigma_loss, sigma_batch_loss,mse_tau,mse_sigma, sigma_f_loss, mse_batch]# these are the different loss functions i have used. I use them as metrics\n",
    "\n",
    "#network structure\n",
    "one_layer=True # this is to switch between one dense layer or two dense layer\n",
    "drop=0.2\n",
    "n_layer_0=48\n",
    "n_layer_1=64\n",
    "n_layer_2=16\n",
    "if kind_of_map!=\"QU\": \n",
    "    n_inputs=n_channels\n",
    "else:\n",
    "    n_inputs=pol*n_channels\n",
    "\n",
    "#train and val\n",
    "batch_size = 16\n",
    "max_epochs = 200\n",
    "lr=0.0003 \n",
    "fval=0.10 # this is the fraction of data that i use for validation \n",
    "training_loss=\"new_sigma_batch\"\n",
    "loss_training=sigma_batch_loss # this is the loss i use for the training\n",
    "shuffle=False\n",
    "\n",
    "f_ = np.load('/home/amorelli/cl_generator/outfile_l_47_complete.npz') \n",
    "#print(\"outfile_R:\",f_.files) #give the keiwords for the stored arrays\n",
    "labels=f_.files\n",
    "data=f_[labels[0]]\n",
    "r=f_[labels[1]]\n",
    "r, data=uf.unison_sorted_copies(r, data)\n",
    "#indexes=np.linspace(0,len(r)-1,10,dtype=int)\n",
    "#r=r[indexes]\n",
    "#data=data[indexes]\n",
    "\n",
    "input_folder=\"/home/amorelli/foreground_noise_maps/noise_generation\"\n",
    "input_files=os.listdir(input_folder)\n",
    "for i in range(len(input_files)):\n",
    "    input_files[i]=input_folder+\"/\"+input_files[i]\n",
    "noise_maps=uf.generate_noise_maps(n_train,n_channels,nside,pol=2,sensitivity=sensitivity,input_files=input_files)\n",
    "print(noise_maps.shape)\n",
    "\n",
    "maps_per_cl_gen=uf.maps_per_cl(distribution=1)\n",
    "maps_per_cl=maps_per_cl_gen.compute_maps_per_cl(r,n_train,n_train_fix)\n",
    "\n",
    "mappe_B,y_r=uf.generate_maps(data, r,n_train=n_train,nside=nside, map_per_cl=maps_per_cl, \n",
    "                             noise_maps=noise_maps, beam_w=2*res, kind_of_map=kind_of_map, raw=0 , n_channels=n_channels,beam_yes=1 , verbose=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "camb-kernel",
   "language": "python",
   "name": "camb-kernel"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
